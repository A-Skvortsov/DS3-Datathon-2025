{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":93278,"databundleVersionId":11116079,"sourceType":"competition"},{"sourceId":264041,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":225851,"modelId":247610}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T02:55:16.322847Z","iopub.execute_input":"2025-02-21T02:55:16.323178Z","iopub.status.idle":"2025-02-21T02:55:16.327886Z","shell.execute_reply.started":"2025-02-21T02:55:16.323156Z","shell.execute_reply":"2025-02-21T02:55:16.326861Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom PIL import Image\n\nclass DenoisingAutoencoder(nn.Module):\n    def __init__(self):\n        super(DenoisingAutoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(True),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(True),\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(True),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.Sigmoid(),  \n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T02:55:16.329199Z","iopub.execute_input":"2025-02-21T02:55:16.329410Z","iopub.status.idle":"2025-02-21T02:55:16.350251Z","shell.execute_reply.started":"2025-02-21T02:55:16.329392Z","shell.execute_reply":"2025-02-21T02:55:16.349367Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Define transformations\ntransform = transforms.Compose([\n    transforms.GaussianBlur(5),\n    transforms.Resize((64, 64)),  # Resize images\n    # transforms.ToTensor(),        # Convert to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n])\n\nto_tensor = transforms.ToTensor()\n\ndae_path = \"/kaggle/input/fungi-dae/pytorch/1/1/dae.pth\"\n\n# Custom dataset class for loading training data from CSV\nclass FungiDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.data = pd.read_csv(csv_file)  # Read CSV file\n        self.root_dir = root_dir  # Use the correct root directory\n        self.transform = transform\n        self.data = self.data[~self.data[\"ClassId\"].isin([1, 3])]\n        #self.dae = DenoisingAutoencoder()\n        #self.dae.load_state_dict(torch.load(dae_path, weights_only=True))\n        #self.dae.eval()\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root_dir, self.data.iloc[idx, 0])  # Combine root and image path\n        \n        # Debugging: Check if the file exists\n        if not os.path.exists(img_path):\n            print(f\"⚠️ Warning: File not found - {img_path}\")  \n        \n        image = Image.open(img_path).convert('RGB')  # Load image\n        label = int(self.data.iloc[idx, 1])  # Get label\n        image = to_tensor(image)\n\n        \"\"\"\n        if label in [1, 3]:\n            with torch.no_grad():\n                image = self.dae(image)\n        \"\"\"\n\n        if self.transform:\n            image = self.transform(image)\n        \n\n        return image, label\n\n    def __len__(self):\n        return len(self.data)\n\n# Load the full dataset from your CSV file\nfull_dataset = FungiDataset(\n    csv_file=\"/kaggle/input/ds-3-datathon-2025-fungi-classification/DatathonFiles/fungi_train.csv\",\n    root_dir=\"/kaggle/input/ds-3-datathon-2025-fungi-classification/DatathonFiles\",\n    transform=transform\n)\nfull_loader = DataLoader(full_dataset, batch_size=32, shuffle=True) # comment this out if you want validation set\n\n# Split the dataset into training and validation sets (80% train, 20% val)\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T02:55:16.351709Z","iopub.execute_input":"2025-02-21T02:55:16.351972Z","iopub.status.idle":"2025-02-21T02:55:16.377175Z","shell.execute_reply.started":"2025-02-21T02:55:16.351953Z","shell.execute_reply":"2025-02-21T02:55:16.376169Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Define a simple CNN model\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes=5):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        # For input 64x64, after three poolings: 64 -> 32 -> 16 -> 8, so 128 * 8 * 8 = 8192\n        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.pool(self.relu(self.conv2(x)))\n        x = self.pool(self.relu(self.conv3(x)))\n        x = torch.flatten(x, 1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Use GPU if available, otherwise use CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nmodel = SimpleCNN(num_classes=5).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T02:55:16.378238Z","iopub.execute_input":"2025-02-21T02:55:16.378442Z","iopub.status.idle":"2025-02-21T02:55:16.422699Z","shell.execute_reply.started":"2025-02-21T02:55:16.378423Z","shell.execute_reply":"2025-02-21T02:55:16.421809Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Training loop with validation\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    # ---- Training ----\n    model.train()\n    running_train_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for images, labels in tqdm(full_loader, desc=f'Training Epoch {epoch+1}/{num_epochs}'):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_train_loss += loss.item() * images.size(0)\n        _, preds = torch.max(outputs, 1)\n        correct_train += (preds == labels).sum().item()\n        total_train += labels.size(0)\n    \n    avg_train_loss = running_train_loss / total_train\n    train_accuracy = 100 * correct_train / total_train\n    \"\"\"\n    # ---- Validation ----; commented out to train on full train set\n    \n    model.eval()\n    running_val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_val_loss += loss.item() * images.size(0)\n            _, preds = torch.max(outputs, 1)\n            correct_val += (preds == labels).sum().item()\n            total_val += labels.size(0)\n    \n    avg_val_loss = running_val_loss / total_val\n    val_accuracy = 100 * correct_val / total_val\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}]: \"\n          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | \"\n          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n    \"\"\"\n    print(f\"Epoch [{epoch+1}/{num_epochs}]: \"\n          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n# Save the trained model\ntorch.save(model.state_dict(), \"fungi.pth\")\nprint(\"Model training completed and saved as 'fungi.pth'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T02:55:16.424265Z","iopub.execute_input":"2025-02-21T02:55:16.424518Z","iopub.status.idle":"2025-02-21T03:00:22.330900Z","shell.execute_reply.started":"2025-02-21T02:55:16.424496Z","shell.execute_reply":"2025-02-21T03:00:22.330063Z"}},"outputs":[{"name":"stderr","text":"Training Epoch 1/15: 100%|██████████| 94/94 [00:23<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/15]: Train Loss: 0.6702, Train Acc: 72.97%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2/15: 100%|██████████| 94/94 [00:20<00:00,  4.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/15]: Train Loss: 0.4455, Train Acc: 83.73%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3/15: 100%|██████████| 94/94 [00:20<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/15]: Train Loss: 0.3881, Train Acc: 85.47%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4/15: 100%|██████████| 94/94 [00:20<00:00,  4.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/15]: Train Loss: 0.2953, Train Acc: 88.83%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5/15: 100%|██████████| 94/94 [00:19<00:00,  4.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/15]: Train Loss: 0.2391, Train Acc: 91.47%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6/15: 100%|██████████| 94/94 [00:20<00:00,  4.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/15]: Train Loss: 0.2495, Train Acc: 90.70%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7/15: 100%|██████████| 94/94 [00:20<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/15]: Train Loss: 0.2016, Train Acc: 92.47%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8/15: 100%|██████████| 94/94 [00:19<00:00,  4.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/15]: Train Loss: 0.2186, Train Acc: 91.37%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9/15: 100%|██████████| 94/94 [00:20<00:00,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/15]: Train Loss: 0.1578, Train Acc: 93.57%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10/15: 100%|██████████| 94/94 [00:19<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/15]: Train Loss: 0.1459, Train Acc: 93.70%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 11/15: 100%|██████████| 94/94 [00:20<00:00,  4.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/15]: Train Loss: 0.1645, Train Acc: 92.90%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 12/15: 100%|██████████| 94/94 [00:19<00:00,  4.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/15]: Train Loss: 0.1604, Train Acc: 93.30%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 13/15: 100%|██████████| 94/94 [00:20<00:00,  4.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/15]: Train Loss: 0.1309, Train Acc: 94.17%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 14/15: 100%|██████████| 94/94 [00:19<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/15]: Train Loss: 0.1079, Train Acc: 95.13%\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 15/15: 100%|██████████| 94/94 [00:20<00:00,  4.67it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [15/15]: Train Loss: 0.1483, Train Acc: 93.80%\nModel training completed and saved as 'fungi.pth'.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Custom dataset class for loading training data from CSV\nclass TestDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.data = pd.read_csv(csv_file)  # Read CSV file\n        self.root_dir = root_dir  # Use the correct root directory\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root_dir, self.data.iloc[idx, 1])  # Combine root and image path\n        \n        # Debugging: Check if the file exists\n        if not os.path.exists(img_path):\n            print(f\"⚠️ Warning: File not found - {img_path}\")  \n        \n        image = Image.open(img_path).convert('RGB')  # Load image\n        id = int(self.data.iloc[idx, 0])  # Get id\n        \n        if self.transform:\n            image = to_tensor(image)\n            image = self.transform(image)\n\n        return image, id\n\n    def __len__(self):\n        return len(self.data)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:00:22.332031Z","iopub.execute_input":"2025-02-21T03:00:22.332336Z","iopub.status.idle":"2025-02-21T03:00:22.338010Z","shell.execute_reply.started":"2025-02-21T03:00:22.332312Z","shell.execute_reply":"2025-02-21T03:00:22.337178Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"test_set = TestDataset(\n    csv_file=\"/kaggle/input/ds-3-datathon-2025-fungi-classification/DatathonFiles/fungi_test.csv\",\n    root_dir=\"/kaggle/input/ds-3-datathon-2025-fungi-classification/DatathonFiles\",\n    transform=transform\n)\ntest_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n\nresults = []\nmodel.eval()\nwith torch.no_grad():  # Disable gradient computation for inference\n    for images, ids in test_loader:\n        outputs = model(images.to(device))\n        _, predicted = torch.max(outputs, 1)  # Get the class with highest probability\n\n        for img_id, pred in zip(ids, predicted):\n            results.append({\"id\": img_id.item(), \"output\": pred.item()})\n\n# Save to CSV\ndf = pd.DataFrame(results)\ndf.to_csv(\"fungi_submission.csv\", index=False)\n\nprint(\"Inference completed. Results saved to fungi_submission.csv.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:00:22.338842Z","iopub.execute_input":"2025-02-21T03:00:22.339127Z","iopub.status.idle":"2025-02-21T03:00:35.981383Z","shell.execute_reply.started":"2025-02-21T03:00:22.339099Z","shell.execute_reply":"2025-02-21T03:00:35.980406Z"}},"outputs":[{"name":"stdout","text":"Inference completed. Results saved to fungi_submission.csv.\n","output_type":"stream"}],"execution_count":33}]}